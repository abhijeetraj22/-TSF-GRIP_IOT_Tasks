{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhijeetraj22/TSF-GRIP_IOT_Tasks/blob/main/TASK_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmDHkvqOpQYp"
      },
      "source": [
        "#GRIP The Sparks Foundation(TSF)\n",
        "**IOT and Computer Vision Internship**\n",
        "\n",
        "##Task-2 Color Identification in Images\n",
        "\n",
        "#####In this task, I tried to \n",
        "- Implement an image color detector which identifies all the colors in an\n",
        "image or video. \n",
        "\n",
        "##Steps - \n",
        "\n",
        "- Step 1 - Importing the Libraries\n",
        "- Step 2 -  Initializing the weights file ,config file and names file for detection\n",
        "- Step 3 - Initializing the pre-trained model\n",
        "- Step 4 - Classes which we are going to predict & Output Layers\n",
        "- Step 5 - Loading & Plotting the image\n",
        "- Step 6 - Extracting Features ie. detecting objects\n",
        "- Step 7 - Lets run this object detection on an image\n",
        "- Conclusion\n",
        "\n",
        "\n",
        "####Created by - Abhijeet Raj Modanwal\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBeYLNB2hrdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c972259-5840-431d-b76f-0206d0483f62"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl1mp6AnnsyX"
      },
      "source": [
        "### STEP 1 - Import libraries\n",
        "Let's first import necessary libraries. We need sklearn for KMeans algorithm, matplotlib.pyplot for plotting graphs, numpy to work with arrays, cv2 to work with image data, collections to use Counter to count values, rgb2lab to convert RGB values and deltaE_cie76 to calculate similarity between colors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "powkmTcUlMnr"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from collections import Counter\n",
        "from skimage.color import rgb2lab, deltaE_cie76\n",
        "import os\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sYpX5bptWK4"
      },
      "source": [
        "\n",
        "### STEP 2 - Working with OpenCV\n",
        "Let's first read a sample image and understand basic operations that we can do on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeOE2eEFiBxD"
      },
      "source": [
        "image = cv2.imread('sample_image.jpg')\n",
        "print(\"The type of this input is {}\".format(type(image)))\n",
        "print(\"Shape: {}\".format(image.shape))\n",
        "plt.imshow(image)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdR5_V8ChLCE"
      },
      "source": [
        "We see that the image has different colors as compared to the original image. This is because by default OpenCV reads the images in the color order BLUE GREEN RED i.e. BGR. Thus, we need to convert it into REG GREEN BLUE i.e. RGB."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8wuhP-AIxYd"
      },
      "source": [
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(image)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xLBpxBzhXNZ"
      },
      "source": [
        "The image can also be converted to grayscale if needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx8y3pBkhaRZ"
      },
      "source": [
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "plt.imshow(gray_image, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B1PyLkkhd2i"
      },
      "source": [
        "We might want to resize the image to a certain size whenever the images are huge or when we are working with multiple images of different dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4nhwP10hhoQ"
      },
      "source": [
        "resized_image = cv2.resize(image, (1200, 600))\n",
        "plt.imshow(resized_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kXfMKczvbPJ"
      },
      "source": [
        "### STEP 3 - Color Identification\n",
        "- *Not that we know a bit about OpenCV, let's start identifying colors from an image.*\n",
        "\n",
        "- First, we will define a function that can give us the hex values of our the colors that we will identify.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoxJN0L0vfri"
      },
      "source": [
        "def RGB2HEX(color):\n",
        "    return \"#{:02x}{:02x}{:02x}\".format(int(color[0]), int(color[1]), int(color[2]))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fRP9Jpkh0ZD"
      },
      "source": [
        "KMeans expects flattened array as input during its fit method. Thus, we need to reshape the image using numpy. Then, we can apply KMeans to first fit and then predict on the image to get the results. Then, the cluster colors are identified an arranged in the correct order. We plot the colors as a pie chart."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4zWz9Nih7Ar"
      },
      "source": [
        "def get_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0lVneZ-h868"
      },
      "source": [
        "def get_colors(image, number_of_colors, show_chart):\n",
        "    \n",
        "    modified_image = cv2.resize(image, (600, 400), interpolation = cv2.INTER_AREA)\n",
        "    modified_image = modified_image.reshape(modified_image.shape[0]*modified_image.shape[1], 3)\n",
        "    \n",
        "    clf = KMeans(n_clusters = number_of_colors)\n",
        "    labels = clf.fit_predict(modified_image)\n",
        "    \n",
        "    counts = Counter(labels)\n",
        "    # sort to ensure correct color percentage\n",
        "    counts = dict(sorted(counts.items()))\n",
        "    \n",
        "    center_colors = clf.cluster_centers_\n",
        "    # We get ordered colors by iterating through the keys\n",
        "    ordered_colors = [center_colors[i] for i in counts.keys()]\n",
        "    hex_colors = [RGB2HEX(ordered_colors[i]) for i in counts.keys()]\n",
        "    rgb_colors = [ordered_colors[i] for i in counts.keys()]\n",
        "\n",
        "    if (show_chart):\n",
        "        plt.figure(figsize = (8, 6))\n",
        "        plt.pie(counts.values(), labels = hex_colors, colors = hex_colors)\n",
        "    \n",
        "    return rgb_colors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrtT4QOFiAsN"
      },
      "source": [
        "get_colors(get_image('sample_image.jpg'), 8, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSeI1Kirtxvp"
      },
      "source": [
        "### STEP 4 - Search images using Color\n",
        "From the model above, we can extract the major colors. This create the opportunity to search for images based on certain colors. We can select a color and if it's hex matches or is close to the hex of the major colors of the image, we say it's a match.\n",
        "\n",
        "We first get all the images and store them in the images variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KJfz1PnI1BE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "215d25de-24d1-4ade-9688-f6a01ca6bb9d"
      },
      "source": [
        "IMAGE_DIRECTORY = 'images'\n",
        "COLORS = {\n",
        "    'GREEN': [0, 128, 0],\n",
        "    'BLUE': [0, 0, 128],\n",
        "    'YELLOW': [255, 255, 0]\n",
        "}\n",
        "images = []\n",
        "\n",
        "for file in os.listdir(IMAGE_DIRECTORY):\n",
        "    if not file.startswith('.'):\n",
        "        images.append(get_image(os.path.join(IMAGE_DIRECTORY, file)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J67UmqvxiSHD"
      },
      "source": [
        "We can now see all the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_ML9G6yiRqd"
      },
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "for i in range(len(images)):\n",
        "    plt.subplot(1, len(images), i+1)\n",
        "    plt.imshow(images[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fx8DvrAiZNu"
      },
      "source": [
        "\n",
        "\n",
        "We define the function below. We will try to match with the top 10 colors of the image. It is highly possible that there will be no extact match for the hex codes, thus we calculate the similarity between the chosen color and the colors of the image.\n",
        "\n",
        "We keep a threshold value such that if the difference between the chosen color and any of the selected colors is less than that threshold, we declare it as a match.\n",
        "\n",
        "Hex values or RGB values cannot be directly compared so we first convert them to a device independant and color uniform space. We use rgb2lab to convert the values and then find the difference using deltaE_cie76. The method calculates the difference between all top 5 colors of the image and the selected color and if atleast one is below the threshold, we show the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ8mRgh8I4oC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d37702-4944-4de4-c689-46ace04039af"
      },
      "source": [
        "def match_image_by_color(image, color, threshold = 60, number_of_colors = 10): \n",
        "    \n",
        "    image_colors = get_colors(image, number_of_colors, False)\n",
        "    selected_color = rgb2lab(np.uint8(np.asarray([[color]])))\n",
        "\n",
        "    select_image = False\n",
        "    for i in range(number_of_colors):\n",
        "        curr_color = rgb2lab(np.uint8(np.asarray([[image_colors[i]]])))\n",
        "        diff = deltaE_cie76(selected_color, curr_color)\n",
        "        if (diff < threshold):\n",
        "            select_image = True\n",
        "    \n",
        "    return select_image"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['conv_0', 'bn_0', 'leaky_1', 'conv_1', 'bn_1', 'leaky_2', 'conv_2', 'bn_2', 'leaky_3', 'conv_3', 'bn_3', 'leaky_4', 'shortcut_4', 'conv_5', 'bn_5', 'leaky_6', 'conv_6', 'bn_6', 'leaky_7', 'conv_7', 'bn_7', 'leaky_8', 'shortcut_8', 'conv_9', 'bn_9', 'leaky_10', 'conv_10', 'bn_10', 'leaky_11', 'shortcut_11', 'conv_12', 'bn_12', 'leaky_13', 'conv_13', 'bn_13', 'leaky_14', 'conv_14', 'bn_14', 'leaky_15', 'shortcut_15', 'conv_16', 'bn_16', 'leaky_17', 'conv_17', 'bn_17', 'leaky_18', 'shortcut_18', 'conv_19', 'bn_19', 'leaky_20', 'conv_20', 'bn_20', 'leaky_21', 'shortcut_21', 'conv_22', 'bn_22', 'leaky_23', 'conv_23', 'bn_23', 'leaky_24', 'shortcut_24', 'conv_25', 'bn_25', 'leaky_26', 'conv_26', 'bn_26', 'leaky_27', 'shortcut_27', 'conv_28', 'bn_28', 'leaky_29', 'conv_29', 'bn_29', 'leaky_30', 'shortcut_30', 'conv_31', 'bn_31', 'leaky_32', 'conv_32', 'bn_32', 'leaky_33', 'shortcut_33', 'conv_34', 'bn_34', 'leaky_35', 'conv_35', 'bn_35', 'leaky_36', 'shortcut_36', 'conv_37', 'bn_37', 'leaky_38', 'conv_38', 'bn_38', 'leaky_39', 'conv_39', 'bn_39', 'leaky_40', 'shortcut_40', 'conv_41', 'bn_41', 'leaky_42', 'conv_42', 'bn_42', 'leaky_43', 'shortcut_43', 'conv_44', 'bn_44', 'leaky_45', 'conv_45', 'bn_45', 'leaky_46', 'shortcut_46', 'conv_47', 'bn_47', 'leaky_48', 'conv_48', 'bn_48', 'leaky_49', 'shortcut_49', 'conv_50', 'bn_50', 'leaky_51', 'conv_51', 'bn_51', 'leaky_52', 'shortcut_52', 'conv_53', 'bn_53', 'leaky_54', 'conv_54', 'bn_54', 'leaky_55', 'shortcut_55', 'conv_56', 'bn_56', 'leaky_57', 'conv_57', 'bn_57', 'leaky_58', 'shortcut_58', 'conv_59', 'bn_59', 'leaky_60', 'conv_60', 'bn_60', 'leaky_61', 'shortcut_61', 'conv_62', 'bn_62', 'leaky_63', 'conv_63', 'bn_63', 'leaky_64', 'conv_64', 'bn_64', 'leaky_65', 'shortcut_65', 'conv_66', 'bn_66', 'leaky_67', 'conv_67', 'bn_67', 'leaky_68', 'shortcut_68', 'conv_69', 'bn_69', 'leaky_70', 'conv_70', 'bn_70', 'leaky_71', 'shortcut_71', 'conv_72', 'bn_72', 'leaky_73', 'conv_73', 'bn_73', 'leaky_74', 'shortcut_74', 'conv_75', 'bn_75', 'leaky_76', 'conv_76', 'bn_76', 'leaky_77', 'conv_77', 'bn_77', 'leaky_78', 'conv_78', 'bn_78', 'leaky_79', 'conv_79', 'bn_79', 'leaky_80', 'conv_80', 'bn_80', 'leaky_81', 'conv_81', 'permute_82', 'yolo_82', 'identity_83', 'conv_84', 'bn_84', 'leaky_85', 'upsample_85', 'concat_86', 'conv_87', 'bn_87', 'leaky_88', 'conv_88', 'bn_88', 'leaky_89', 'conv_89', 'bn_89', 'leaky_90', 'conv_90', 'bn_90', 'leaky_91', 'conv_91', 'bn_91', 'leaky_92', 'conv_92', 'bn_92', 'leaky_93', 'conv_93', 'permute_94', 'yolo_94', 'identity_95', 'conv_96', 'bn_96', 'leaky_97', 'upsample_97', 'concat_98', 'conv_99', 'bn_99', 'leaky_100', 'conv_100', 'bn_100', 'leaky_101', 'conv_101', 'bn_101', 'leaky_102', 'conv_102', 'bn_102', 'leaky_103', 'conv_103', 'bn_103', 'leaky_104', 'conv_104', 'bn_104', 'leaky_105', 'conv_105', 'permute_106', 'yolo_106']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3nGInaQiiYP"
      },
      "source": [
        " We call the above method for all the images in our set and show relevant images out of the same that approximately match our selected color."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJPZmbdsJAKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "921d6d55-796a-4a26-841e-bf699daad912"
      },
      "source": [
        "def show_selected_images(images, color, threshold, colors_to_match):\n",
        "    index = 1\n",
        "    \n",
        "    for i in range(len(images)):\n",
        "        selected = match_image_by_color(images[i],\n",
        "                                        color,\n",
        "                                        threshold,\n",
        "                                        colors_to_match)\n",
        "        if (selected):\n",
        "            plt.subplot(1, 5, index)\n",
        "            plt.imshow(images[i])\n",
        "            index += 1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[200],\n",
              "       [227],\n",
              "       [254]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65853ekTJCcZ"
      },
      "source": [
        "# Search for GREEN\n",
        "plt.figure(figsize = (20, 10))\n",
        "show_selected_images(images, COLORS['GREEN'], 60, 5)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YEEtwRFJEd2"
      },
      "source": [
        "# Search for BLUE\n",
        "plt.figure(figsize = (20, 10))\n",
        "show_selected_images(images, COLORS['BLUE'], 60, 5)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jC4H7WUJGbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4c06e1-b4ca-4d00-cc18-527ad068e7bd"
      },
      "source": [
        "# Search for YELLOW\n",
        "plt.figure(figsize = (20, 10))\n",
        "show_selected_images(images, COLORS['YELLOW'], 60, 5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yolo_82', 'yolo_94', 'yolo_106']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CDkRmFh6Yyx"
      },
      "source": [
        "\n",
        "### Conclusion\n",
        "\n",
        "*In this notebook, we used KMeans to extract majority colors from images. We then used the RGB Values of Colors to identify images from a collection that have that color in them.*\n"
      ]
    }
  ]
}